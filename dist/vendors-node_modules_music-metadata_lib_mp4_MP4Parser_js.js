"use strict";
/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
(self["webpackChunk"] = self["webpackChunk"] || []).push([["vendors-node_modules_music-metadata_lib_mp4_MP4Parser_js"],{

/***/ "./node_modules/music-metadata/lib/mp4/Atom.js":
/*!*****************************************************!*\
  !*** ./node_modules/music-metadata/lib/mp4/Atom.js ***!
  \*****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Atom: () => (/* binding */ Atom)\n/* harmony export */ });\n/* harmony import */ var debug__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! debug */ \"./node_modules/debug/src/browser.js\");\n/* harmony import */ var _AtomToken_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./AtomToken.js */ \"./node_modules/music-metadata/lib/mp4/AtomToken.js\");\n\n\n\nconst debug = debug__WEBPACK_IMPORTED_MODULE_0__('music-metadata:parser:MP4:Atom');\nclass Atom {\n    static async readAtom(tokenizer, dataHandler, parent, remaining) {\n        // Parse atom header\n        const offset = tokenizer.position;\n        debug(`Reading next token on offset=${offset}...`); //  buf.toString('ascii')\n        const header = await tokenizer.readToken(_AtomToken_js__WEBPACK_IMPORTED_MODULE_1__.Header);\n        const extended = header.length === 1n;\n        if (extended) {\n            header.length = await tokenizer.readToken(_AtomToken_js__WEBPACK_IMPORTED_MODULE_1__.ExtendedSize);\n        }\n        const atomBean = new Atom(header, extended, parent);\n        const payloadLength = atomBean.getPayloadLength(remaining);\n        debug(`parse atom name=${atomBean.atomPath}, extended=${atomBean.extended}, offset=${offset}, len=${atomBean.header.length}`); //  buf.toString('ascii')\n        await atomBean.readData(tokenizer, dataHandler, payloadLength);\n        return atomBean;\n    }\n    constructor(header, extended, parent) {\n        this.header = header;\n        this.extended = extended;\n        this.parent = parent;\n        this.children = [];\n        this.atomPath = (this.parent ? `${this.parent.atomPath}.` : '') + this.header.name;\n    }\n    getHeaderLength() {\n        return this.extended ? 16 : 8;\n    }\n    getPayloadLength(remaining) {\n        return (this.header.length === 0n ? remaining : Number(this.header.length)) - this.getHeaderLength();\n    }\n    async readAtoms(tokenizer, dataHandler, size) {\n        while (size > 0) {\n            const atomBean = await Atom.readAtom(tokenizer, dataHandler, this, size);\n            this.children.push(atomBean);\n            size -= atomBean.header.length === 0n ? size : Number(atomBean.header.length);\n        }\n    }\n    async readData(tokenizer, dataHandler, remaining) {\n        switch (this.header.name) {\n            // \"Container\" atoms, contains nested atoms\n            case 'moov': // The Movie Atom: contains other atoms\n            case 'udta': // User defined atom\n            case 'mdia': // Media atom\n            case 'minf': // Media Information Atom\n            case 'stbl': // The Sample Table Atom\n            case '<id>':\n            case 'ilst':\n            case 'tref':\n            case 'moof':\n                return this.readAtoms(tokenizer, dataHandler, this.getPayloadLength(remaining));\n            case 'meta': { // Metadata Atom, ref: https://developer.apple.com/library/content/documentation/QuickTime/QTFF/Metadata/Metadata.html#//apple_ref/doc/uid/TP40000939-CH1-SW8\n                // meta has 4 bytes of padding, ignore\n                const peekHeader = await tokenizer.peekToken(_AtomToken_js__WEBPACK_IMPORTED_MODULE_1__.Header);\n                const paddingLength = peekHeader.name === 'hdlr' ? 0 : 4;\n                await tokenizer.ignore(paddingLength);\n                return this.readAtoms(tokenizer, dataHandler, this.getPayloadLength(remaining) - paddingLength);\n            }\n            default:\n                return dataHandler(this, remaining);\n        }\n    }\n}\n//# sourceMappingURL=Atom.js.map\n\n//# sourceURL=webpack:///./node_modules/music-metadata/lib/mp4/Atom.js?\n}");

/***/ }),

/***/ "./node_modules/music-metadata/lib/mp4/AtomToken.js":
/*!**********************************************************!*\
  !*** ./node_modules/music-metadata/lib/mp4/AtomToken.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ChapterText: () => (/* binding */ ChapterText),\n/* harmony export */   ChapterTrackReferenceBox: () => (/* binding */ ChapterTrackReferenceBox),\n/* harmony export */   DataAtom: () => (/* binding */ DataAtom),\n/* harmony export */   ExtendedSize: () => (/* binding */ ExtendedSize),\n/* harmony export */   FixedLengthAtom: () => (/* binding */ FixedLengthAtom),\n/* harmony export */   HandlerBox: () => (/* binding */ HandlerBox),\n/* harmony export */   Header: () => (/* binding */ Header),\n/* harmony export */   MdhdAtom: () => (/* binding */ MdhdAtom),\n/* harmony export */   Mp4ContentError: () => (/* binding */ Mp4ContentError),\n/* harmony export */   MvhdAtom: () => (/* binding */ MvhdAtom),\n/* harmony export */   NameAtom: () => (/* binding */ NameAtom),\n/* harmony export */   SampleToChunkToken: () => (/* binding */ SampleToChunkToken),\n/* harmony export */   SoundSampleDescriptionV0: () => (/* binding */ SoundSampleDescriptionV0),\n/* harmony export */   SoundSampleDescriptionVersion: () => (/* binding */ SoundSampleDescriptionVersion),\n/* harmony export */   StcoAtom: () => (/* binding */ StcoAtom),\n/* harmony export */   StscAtom: () => (/* binding */ StscAtom),\n/* harmony export */   StsdAtom: () => (/* binding */ StsdAtom),\n/* harmony export */   StszAtom: () => (/* binding */ StszAtom),\n/* harmony export */   SttsAtom: () => (/* binding */ SttsAtom),\n/* harmony export */   TimeToSampleToken: () => (/* binding */ TimeToSampleToken),\n/* harmony export */   TrackFragmentHeaderBox: () => (/* binding */ TrackFragmentHeaderBox),\n/* harmony export */   TrackHeaderAtom: () => (/* binding */ TrackHeaderAtom),\n/* harmony export */   TrackRunBox: () => (/* binding */ TrackRunBox),\n/* harmony export */   ftyp: () => (/* binding */ ftyp),\n/* harmony export */   mhdr: () => (/* binding */ mhdr)\n/* harmony export */ });\n/* harmony import */ var token_types__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! token-types */ \"./node_modules/token-types/lib/index.js\");\n/* harmony import */ var debug__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! debug */ \"./node_modules/debug/src/browser.js\");\n/* harmony import */ var _common_FourCC_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/FourCC.js */ \"./node_modules/music-metadata/lib/common/FourCC.js\");\n/* harmony import */ var _ParseError_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../ParseError.js */ \"./node_modules/music-metadata/lib/ParseError.js\");\n/* harmony import */ var _common_Util_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common/Util.js */ \"./node_modules/music-metadata/lib/common/Util.js\");\n\n\n\n\n\nconst debug = debug__WEBPACK_IMPORTED_MODULE_1__('music-metadata:parser:MP4:atom');\nclass Mp4ContentError extends (0,_ParseError_js__WEBPACK_IMPORTED_MODULE_2__.makeUnexpectedFileContentError)('MP4') {\n}\nconst Header = {\n    len: 8,\n    get: (buf, off) => {\n        const length = token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off);\n        if (length < 0)\n            throw new Mp4ContentError('Invalid atom header length');\n        return {\n            length: BigInt(length),\n            name: new token_types__WEBPACK_IMPORTED_MODULE_0__.StringType(4, 'latin1').get(buf, off + 4)\n        };\n    },\n    put: (buf, off, hdr) => {\n        token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.put(buf, off, Number(hdr.length));\n        return _common_FourCC_js__WEBPACK_IMPORTED_MODULE_3__.FourCcToken.put(buf, off + 4, hdr.name);\n    }\n};\n/**\n * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap1/qtff1.html#//apple_ref/doc/uid/TP40000939-CH203-38190\n */\nconst ExtendedSize = token_types__WEBPACK_IMPORTED_MODULE_0__.UINT64_BE;\nconst ftyp = {\n    len: 4,\n    get: (buf, off) => {\n        return {\n            type: new token_types__WEBPACK_IMPORTED_MODULE_0__.StringType(4, 'ascii').get(buf, off)\n        };\n    }\n};\n/**\n * Token: Movie Header Atom\n */\nconst mhdr = {\n    len: 8,\n    get: (buf, off) => {\n        return {\n            version: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT8.get(buf, off),\n            flags: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT24_BE.get(buf, off + 1),\n            nextItemID: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off + 4)\n        };\n    }\n};\n/**\n * Base class for 'fixed' length atoms.\n * In some cases these atoms are longer then the sum of the described fields.\n * Issue: https://github.com/Borewit/music-metadata/issues/120\n */\nclass FixedLengthAtom {\n    /**\n     *\n     * @param {number} len Length as specified in the size field\n     * @param {number} expLen Total length of sum of specified fields in the standard\n     * @param atomId Atom ID\n     */\n    constructor(len, expLen, atomId) {\n        if (len < expLen) {\n            throw new Mp4ContentError(`Atom ${atomId} expected to be ${expLen}, but specifies ${len} bytes long.`);\n        }\n        if (len > expLen) {\n            debug(`Warning: atom ${atomId} expected to be ${expLen}, but was actually ${len} bytes long.`);\n        }\n        this.len = len;\n    }\n}\n/**\n * Timestamp stored in seconds since Mac Epoch (1 January 1904)\n */\nconst SecondsSinceMacEpoch = {\n    len: 4,\n    get: (buf, off) => {\n        const secondsSinceUnixEpoch = token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off) - 2082844800;\n        return new Date(secondsSinceUnixEpoch * 1000);\n    }\n};\n/**\n * Token: Media Header Atom\n * Ref:\n * - https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-SW34\n * - https://wiki.multimedia.cx/index.php/QuickTime_container#mdhd\n */\nclass MdhdAtom extends FixedLengthAtom {\n    constructor(len) {\n        super(len, 24, 'mdhd');\n    }\n    get(buf, off) {\n        return {\n            version: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT8.get(buf, off + 0),\n            flags: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT24_BE.get(buf, off + 1),\n            creationTime: SecondsSinceMacEpoch.get(buf, off + 4),\n            modificationTime: SecondsSinceMacEpoch.get(buf, off + 8),\n            timeScale: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off + 12),\n            duration: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off + 16),\n            language: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT16_BE.get(buf, off + 20),\n            quality: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT16_BE.get(buf, off + 22)\n        };\n    }\n}\n/**\n * Token: Movie Header Atom\n */\nclass MvhdAtom extends FixedLengthAtom {\n    constructor(len) {\n        super(len, 100, 'mvhd');\n    }\n    get(buf, off) {\n        return {\n            version: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT8.get(buf, off),\n            flags: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT24_BE.get(buf, off + 1),\n            creationTime: SecondsSinceMacEpoch.get(buf, off + 4),\n            modificationTime: SecondsSinceMacEpoch.get(buf, off + 8),\n            timeScale: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off + 12),\n            duration: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off + 16),\n            preferredRate: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off + 20),\n            preferredVolume: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT16_BE.get(buf, off + 24),\n            // ignore reserver: 10 bytes\n            // ignore matrix structure: 36 bytes\n            previewTime: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off + 72),\n            previewDuration: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off + 76),\n            posterTime: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off + 80),\n            selectionTime: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off + 84),\n            selectionDuration: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off + 88),\n            currentTime: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off + 92),\n            nextTrackID: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off + 96)\n        };\n    }\n}\n/**\n * Data Atom Structure\n */\nclass DataAtom {\n    constructor(len) {\n        this.len = len;\n    }\n    get(buf, off) {\n        return {\n            type: {\n                set: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT8.get(buf, off + 0),\n                type: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT24_BE.get(buf, off + 1)\n            },\n            locale: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT24_BE.get(buf, off + 4),\n            value: new token_types__WEBPACK_IMPORTED_MODULE_0__.Uint8ArrayType(this.len - 8).get(buf, off + 8)\n        };\n    }\n}\n/**\n * Data Atom Structure\n * Ref: https://developer.apple.com/library/content/documentation/QuickTime/QTFF/Metadata/Metadata.html#//apple_ref/doc/uid/TP40000939-CH1-SW31\n */\nclass NameAtom {\n    constructor(len) {\n        this.len = len;\n    }\n    get(buf, off) {\n        return {\n            version: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT8.get(buf, off),\n            flags: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT24_BE.get(buf, off + 1),\n            name: new token_types__WEBPACK_IMPORTED_MODULE_0__.StringType(this.len - 4, 'utf-8').get(buf, off + 4)\n        };\n    }\n}\n/**\n * Track Header Atoms structure (`tkhd`)\n * Ref: https://developer.apple.com/library/content/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-25550\n */\nclass TrackHeaderAtom {\n    constructor(len) {\n        this.len = len;\n    }\n    get(buf, off) {\n        return {\n            version: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT8.get(buf, off),\n            flags: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT24_BE.get(buf, off + 1),\n            creationTime: SecondsSinceMacEpoch.get(buf, off + 4),\n            modificationTime: SecondsSinceMacEpoch.get(buf, off + 8),\n            trackId: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off + 12),\n            // reserved 4 bytes\n            duration: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off + 20),\n            layer: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT16_BE.get(buf, off + 24),\n            alternateGroup: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT16_BE.get(buf, off + 26),\n            volume: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT16_BE.get(buf, off + 28) // ToDo: fixed point\n            // ToDo: add remaining fields\n        };\n    }\n}\n/**\n * Atom: Sample Description Atom ('stsd')\n * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-25691\n */\nconst stsdHeader = {\n    len: 8,\n    get: (buf, off) => {\n        return {\n            version: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT8.get(buf, off),\n            flags: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT24_BE.get(buf, off + 1),\n            numberOfEntries: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off + 4)\n        };\n    }\n};\n/**\n * Atom: Sample Description Atom ('stsd')\n * Ref: https://developer.apple.com/documentation/quicktime-file-format/sample_description_atom\n */\nclass SampleDescriptionTable {\n    constructor(len) {\n        this.len = len;\n    }\n    get(buf, off) {\n        const descrLen = this.len - 12;\n        return {\n            dataFormat: _common_FourCC_js__WEBPACK_IMPORTED_MODULE_3__.FourCcToken.get(buf, off),\n            dataReferenceIndex: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT16_BE.get(buf, off + 10),\n            description: descrLen > 0 ? new token_types__WEBPACK_IMPORTED_MODULE_0__.Uint8ArrayType(descrLen).get(buf, off + 12) : undefined\n        };\n    }\n}\n/**\n * Atom: Sample-description Atom ('stsd')\n * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-25691\n */\nclass StsdAtom {\n    constructor(len) {\n        this.len = len;\n    }\n    get(buf, off) {\n        const header = stsdHeader.get(buf, off);\n        off += stsdHeader.len;\n        const table = [];\n        for (let n = 0; n < header.numberOfEntries; ++n) {\n            const size = token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off); // Sample description size\n            off += token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.len;\n            table.push(new SampleDescriptionTable(size - token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.len).get(buf, off));\n            off += size;\n        }\n        return {\n            header,\n            table\n        };\n    }\n}\n/**\n * Common Sound Sample Description (version & revision)\n * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap3/qtff3.html#//apple_ref/doc/uid/TP40000939-CH205-57317\n */\nconst SoundSampleDescriptionVersion = {\n    len: 8,\n    get(buf, off) {\n        return {\n            version: token_types__WEBPACK_IMPORTED_MODULE_0__.INT16_BE.get(buf, off),\n            revision: token_types__WEBPACK_IMPORTED_MODULE_0__.INT16_BE.get(buf, off + 2),\n            vendor: token_types__WEBPACK_IMPORTED_MODULE_0__.INT32_BE.get(buf, off + 4)\n        };\n    }\n};\n/**\n * Sound Sample Description (Version 0)\n * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap3/qtff3.html#//apple_ref/doc/uid/TP40000939-CH205-130736\n */\nconst SoundSampleDescriptionV0 = {\n    len: 12,\n    get(buf, off) {\n        return {\n            numAudioChannels: token_types__WEBPACK_IMPORTED_MODULE_0__.INT16_BE.get(buf, off + 0),\n            sampleSize: token_types__WEBPACK_IMPORTED_MODULE_0__.INT16_BE.get(buf, off + 2),\n            compressionId: token_types__WEBPACK_IMPORTED_MODULE_0__.INT16_BE.get(buf, off + 4),\n            packetSize: token_types__WEBPACK_IMPORTED_MODULE_0__.INT16_BE.get(buf, off + 6),\n            sampleRate: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT16_BE.get(buf, off + 8) + token_types__WEBPACK_IMPORTED_MODULE_0__.UINT16_BE.get(buf, off + 10) / 10000\n        };\n    }\n};\nclass SimpleTableAtom {\n    constructor(len, token) {\n        this.len = len;\n        this.token = token;\n    }\n    get(buf, off) {\n        const nrOfEntries = token_types__WEBPACK_IMPORTED_MODULE_0__.INT32_BE.get(buf, off + 4);\n        return {\n            version: token_types__WEBPACK_IMPORTED_MODULE_0__.INT8.get(buf, off + 0),\n            flags: token_types__WEBPACK_IMPORTED_MODULE_0__.INT24_BE.get(buf, off + 1),\n            numberOfEntries: nrOfEntries,\n            entries: readTokenTable(buf, this.token, off + 8, this.len - 8, nrOfEntries)\n        };\n    }\n}\nconst TimeToSampleToken = {\n    len: 8,\n    get(buf, off) {\n        return {\n            count: token_types__WEBPACK_IMPORTED_MODULE_0__.INT32_BE.get(buf, off + 0),\n            duration: token_types__WEBPACK_IMPORTED_MODULE_0__.INT32_BE.get(buf, off + 4)\n        };\n    }\n};\n/**\n * Time-to-sample('stts') atom.\n * Store duration information for a mediaâ€™s samples.\n * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-25696\n */\nclass SttsAtom extends SimpleTableAtom {\n    constructor(len) {\n        super(len, TimeToSampleToken);\n    }\n}\nconst SampleToChunkToken = {\n    len: 12,\n    get(buf, off) {\n        return {\n            firstChunk: token_types__WEBPACK_IMPORTED_MODULE_0__.INT32_BE.get(buf, off),\n            samplesPerChunk: token_types__WEBPACK_IMPORTED_MODULE_0__.INT32_BE.get(buf, off + 4),\n            sampleDescriptionId: token_types__WEBPACK_IMPORTED_MODULE_0__.INT32_BE.get(buf, off + 8)\n        };\n    }\n};\n/**\n * Sample-to-Chunk ('stsc') atom interface\n * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-25706\n */\nclass StscAtom extends SimpleTableAtom {\n    constructor(len) {\n        super(len, SampleToChunkToken);\n    }\n}\n/**\n * Sample-size ('stsz') atom\n * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-25710\n */\nclass StszAtom {\n    constructor(len) {\n        this.len = len;\n    }\n    get(buf, off) {\n        const nrOfEntries = token_types__WEBPACK_IMPORTED_MODULE_0__.INT32_BE.get(buf, off + 8);\n        return {\n            version: token_types__WEBPACK_IMPORTED_MODULE_0__.INT8.get(buf, off),\n            flags: token_types__WEBPACK_IMPORTED_MODULE_0__.INT24_BE.get(buf, off + 1),\n            sampleSize: token_types__WEBPACK_IMPORTED_MODULE_0__.INT32_BE.get(buf, off + 4),\n            numberOfEntries: nrOfEntries,\n            entries: readTokenTable(buf, token_types__WEBPACK_IMPORTED_MODULE_0__.INT32_BE, off + 12, this.len - 12, nrOfEntries)\n        };\n    }\n}\n/**\n * Chunk offset atom, 'stco'\n * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-25715\n */\nclass StcoAtom extends SimpleTableAtom {\n    constructor(len) {\n        super(len, token_types__WEBPACK_IMPORTED_MODULE_0__.INT32_BE);\n        this.len = len;\n    }\n}\n/**\n * Token used to decode text-track from 'mdat' atom (raw data stream)\n */\nclass ChapterText {\n    constructor(len) {\n        this.len = len;\n    }\n    get(buf, off) {\n        const titleLen = token_types__WEBPACK_IMPORTED_MODULE_0__.INT16_BE.get(buf, off + 0);\n        const str = new token_types__WEBPACK_IMPORTED_MODULE_0__.StringType(titleLen, 'utf-8');\n        return str.get(buf, off + 2);\n    }\n}\nfunction readTokenTable(buf, token, off, remainingLen, numberOfEntries) {\n    debug(`remainingLen=${remainingLen}, numberOfEntries=${numberOfEntries} * token-len=${token.len}`);\n    if (remainingLen === 0)\n        return [];\n    if (remainingLen !== numberOfEntries * token.len)\n        throw new Mp4ContentError('mismatch number-of-entries with remaining atom-length');\n    const entries = [];\n    // parse offset-table\n    for (let n = 0; n < numberOfEntries; ++n) {\n        entries.push(token.get(buf, off));\n        off += token.len;\n    }\n    return entries;\n}\n/**\n * Sample-size ('tfhd') TrackFragmentHeaderBox\n */\nclass TrackFragmentHeaderBox {\n    constructor(len) {\n        this.len = len;\n    }\n    get(buf, off) {\n        const flagOffset = off + 1;\n        const header = {\n            version: token_types__WEBPACK_IMPORTED_MODULE_0__.INT8.get(buf, off),\n            flags: {\n                baseDataOffsetPresent: _common_Util_js__WEBPACK_IMPORTED_MODULE_4__.getBit(buf, flagOffset + 2, 0),\n                sampleDescriptionIndexPresent: _common_Util_js__WEBPACK_IMPORTED_MODULE_4__.getBit(buf, flagOffset + 2, 1),\n                defaultSampleDurationPresent: _common_Util_js__WEBPACK_IMPORTED_MODULE_4__.getBit(buf, flagOffset + 2, 3),\n                defaultSampleSizePresent: _common_Util_js__WEBPACK_IMPORTED_MODULE_4__.getBit(buf, flagOffset + 2, 4),\n                defaultSampleFlagsPresent: _common_Util_js__WEBPACK_IMPORTED_MODULE_4__.getBit(buf, flagOffset + 2, 5),\n                defaultDurationIsEmpty: _common_Util_js__WEBPACK_IMPORTED_MODULE_4__.getBit(buf, flagOffset, 0),\n                defaultBaseIsMoof: _common_Util_js__WEBPACK_IMPORTED_MODULE_4__.getBit(buf, flagOffset, 1)\n            },\n            trackId: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, 4)\n        };\n        let dynOffset = 8;\n        if (header.flags.baseDataOffsetPresent) {\n            header.baseDataOffset = token_types__WEBPACK_IMPORTED_MODULE_0__.UINT64_BE.get(buf, dynOffset);\n            dynOffset += 8;\n        }\n        if (header.flags.sampleDescriptionIndexPresent) {\n            header.sampleDescriptionIndex = token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, dynOffset);\n            dynOffset += 4;\n        }\n        if (header.flags.defaultSampleDurationPresent) {\n            header.defaultSampleDuration = token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, dynOffset);\n            dynOffset += 4;\n        }\n        if (header.flags.defaultSampleSizePresent) {\n            header.defaultSampleSize = token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, dynOffset);\n            dynOffset += 4;\n        }\n        if (header.flags.defaultSampleFlagsPresent) {\n            header.defaultSampleFlags = token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, dynOffset);\n        }\n        return header;\n    }\n}\n/**\n * Sample-size ('trun') TrackRunBox\n */\nclass TrackRunBox {\n    constructor(len) {\n        this.len = len;\n    }\n    get(buf, off) {\n        const flagOffset = off + 1;\n        const trun = {\n            version: token_types__WEBPACK_IMPORTED_MODULE_0__.INT8.get(buf, off),\n            flags: {\n                dataOffsetPresent: _common_Util_js__WEBPACK_IMPORTED_MODULE_4__.getBit(buf, flagOffset + 2, 0),\n                firstSampleFlagsPresent: _common_Util_js__WEBPACK_IMPORTED_MODULE_4__.getBit(buf, flagOffset + 2, 2),\n                sampleDurationPresent: _common_Util_js__WEBPACK_IMPORTED_MODULE_4__.getBit(buf, flagOffset + 1, 0),\n                sampleSizePresent: _common_Util_js__WEBPACK_IMPORTED_MODULE_4__.getBit(buf, flagOffset + 1, 1),\n                sampleFlagsPresent: _common_Util_js__WEBPACK_IMPORTED_MODULE_4__.getBit(buf, flagOffset + 1, 2),\n                sampleCompositionTimeOffsetsPresent: _common_Util_js__WEBPACK_IMPORTED_MODULE_4__.getBit(buf, flagOffset + 1, 3)\n            },\n            sampleCount: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off + 4),\n            samples: []\n        };\n        let dynOffset = off + 8;\n        if (trun.flags.dataOffsetPresent) {\n            trun.dataOffset = token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, dynOffset);\n            dynOffset += 4;\n        }\n        if (trun.flags.firstSampleFlagsPresent) {\n            trun.firstSampleFlags = token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, dynOffset);\n            dynOffset += 4;\n        }\n        for (let n = 0; n < trun.sampleCount; ++n) {\n            if (dynOffset >= this.len) {\n                debug(\"TrackRunBox size mismatch\");\n                break;\n            }\n            const sample = {};\n            if (trun.flags.sampleDurationPresent) {\n                sample.sampleDuration = token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, dynOffset);\n                dynOffset += 4;\n            }\n            if (trun.flags.sampleSizePresent) {\n                sample.sampleSize = token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, dynOffset);\n                dynOffset += 4;\n            }\n            if (trun.flags.sampleFlagsPresent) {\n                sample.sampleFlags = token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, dynOffset);\n                dynOffset += 4;\n            }\n            if (trun.flags.sampleCompositionTimeOffsetsPresent) {\n                sample.sampleCompositionTimeOffset = token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, dynOffset);\n                dynOffset += 4;\n            }\n            trun.samples.push(sample);\n        }\n        return trun;\n    }\n}\n/**\n * HandlerBox (`hdlr`)\n */\nclass HandlerBox {\n    constructor(len) {\n        this.len = len;\n    }\n    get(buf, off) {\n        const _flagOffset = off + 1;\n        const charTypeToken = new token_types__WEBPACK_IMPORTED_MODULE_0__.StringType(4, 'utf-8');\n        return {\n            version: token_types__WEBPACK_IMPORTED_MODULE_0__.INT8.get(buf, off),\n            flags: token_types__WEBPACK_IMPORTED_MODULE_0__.UINT24_BE.get(buf, off + 1),\n            componentType: charTypeToken.get(buf, off + 4),\n            handlerType: charTypeToken.get(buf, off + 8),\n            componentName: new token_types__WEBPACK_IMPORTED_MODULE_0__.StringType(this.len - 28, 'utf-8').get(buf, off + 28),\n        };\n    }\n}\n/**\n * Chapter Track Reference Box (`chap`)\n */\nclass ChapterTrackReferenceBox {\n    constructor(len) {\n        this.len = len;\n    }\n    get(buf, off) {\n        let dynOffset = 0;\n        const trackIds = [];\n        while (dynOffset < this.len) {\n            trackIds.push(token_types__WEBPACK_IMPORTED_MODULE_0__.UINT32_BE.get(buf, off + dynOffset));\n            dynOffset += 4;\n        }\n        return trackIds;\n    }\n}\n//# sourceMappingURL=AtomToken.js.map\n\n//# sourceURL=webpack:///./node_modules/music-metadata/lib/mp4/AtomToken.js?\n}");

/***/ }),

/***/ "./node_modules/music-metadata/lib/mp4/MP4Parser.js":
/*!**********************************************************!*\
  !*** ./node_modules/music-metadata/lib/mp4/MP4Parser.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("{__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   MP4Parser: () => (/* binding */ MP4Parser)\n/* harmony export */ });\n/* harmony import */ var debug__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! debug */ \"./node_modules/debug/src/browser.js\");\n/* harmony import */ var token_types__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! token-types */ \"./node_modules/token-types/lib/index.js\");\n/* harmony import */ var _common_BasicParser_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/BasicParser.js */ \"./node_modules/music-metadata/lib/common/BasicParser.js\");\n/* harmony import */ var _id3v1_ID3v1Parser_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../id3v1/ID3v1Parser.js */ \"./node_modules/music-metadata/lib/id3v1/ID3v1Parser.js\");\n/* harmony import */ var _Atom_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Atom.js */ \"./node_modules/music-metadata/lib/mp4/Atom.js\");\n/* harmony import */ var _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./AtomToken.js */ \"./node_modules/music-metadata/lib/mp4/AtomToken.js\");\n/* harmony import */ var _type_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../type.js */ \"./node_modules/music-metadata/lib/matroska/types.js\");\n/* harmony import */ var uint8array_extras__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! uint8array-extras */ \"./node_modules/uint8array-extras/index.js\");\n\n\n\n\n\n\n\n\n\nconst debug = debug__WEBPACK_IMPORTED_MODULE_0__('music-metadata:parser:MP4');\nconst tagFormat = 'iTunes';\nconst encoderDict = {\n    raw: {\n        lossy: false,\n        format: 'raw'\n    },\n    MAC3: {\n        lossy: true,\n        format: 'MACE 3:1'\n    },\n    MAC6: {\n        lossy: true,\n        format: 'MACE 6:1'\n    },\n    ima4: {\n        lossy: true,\n        format: 'IMA 4:1'\n    },\n    ulaw: {\n        lossy: true,\n        format: 'uLaw 2:1'\n    },\n    alaw: {\n        lossy: true,\n        format: 'uLaw 2:1'\n    },\n    Qclp: {\n        lossy: true,\n        format: 'QUALCOMM PureVoice'\n    },\n    '.mp3': {\n        lossy: true,\n        format: 'MPEG-1 layer 3'\n    },\n    alac: {\n        lossy: false,\n        format: 'ALAC'\n    },\n    'ac-3': {\n        lossy: true,\n        format: 'AC-3'\n    },\n    mp4a: {\n        lossy: true,\n        format: 'MPEG-4/AAC'\n    },\n    mp4s: {\n        lossy: true,\n        format: 'MP4S'\n    },\n    // Closed Captioning Media, https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap3/qtff3.html#//apple_ref/doc/uid/TP40000939-CH205-SW87\n    c608: {\n        lossy: true,\n        format: 'CEA-608'\n    },\n    c708: {\n        lossy: true,\n        format: 'CEA-708'\n    }\n};\nfunction distinct(value, index, self) {\n    return self.indexOf(value) === index;\n}\n/*\n * Parser for the MP4 (MPEG-4 Part 14) container format\n * Standard: ISO/IEC 14496-14\n * supporting:\n * - QuickTime container\n * - MP4 File Format\n * - 3GPP file format\n * - 3GPP2 file format\n *\n * MPEG-4 Audio / Part 3 (.m4a)& MPEG 4 Video (m4v, mp4) extension.\n * Support for Apple iTunes tags as found in a M4A/M4V files.\n * Ref:\n *   https://en.wikipedia.org/wiki/ISO_base_media_file_format\n *   https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/Metadata/Metadata.html\n *   http://atomicparsley.sourceforge.net/mpeg-4files.html\n *   https://github.com/sergiomb2/libmp4v2/wiki/iTunesMetadata\n *   https://wiki.multimedia.cx/index.php/QuickTime_container\n */\nclass MP4Parser extends _common_BasicParser_js__WEBPACK_IMPORTED_MODULE_2__.BasicParser {\n    constructor() {\n        super(...arguments);\n        this.tracks = new Map();\n        this.hasVideoTrack = false;\n        this.hasAudioTrack = true;\n        this.atomParsers = {\n            /**\n             * Parse movie header (mvhd) atom\n             * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-56313\n             */\n            mvhd: async (len) => {\n                const mvhd = await this.tokenizer.readToken(new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.MvhdAtom(len));\n                this.metadata.setFormat('creationTime', mvhd.creationTime);\n                this.metadata.setFormat('modificationTime', mvhd.modificationTime);\n            },\n            chap: async (len) => {\n                const td = this.getTrackDescription();\n                const trackIds = [];\n                while (len >= token_types__WEBPACK_IMPORTED_MODULE_1__.UINT32_BE.len) {\n                    trackIds.push(await this.tokenizer.readNumber(token_types__WEBPACK_IMPORTED_MODULE_1__.UINT32_BE));\n                    len -= token_types__WEBPACK_IMPORTED_MODULE_1__.UINT32_BE.len;\n                }\n                td.chapterList = trackIds;\n            },\n            /**\n             * Parse mdat atom.\n             * Will scan for chapters\n             */\n            mdat: async (len) => {\n                this.audioLengthInBytes = len;\n                this.calculateBitRate();\n                if (this.options.includeChapters) {\n                    const trackWithChapters = [...this.tracks.values()].filter(track => track.chapterList);\n                    if (trackWithChapters.length === 1) {\n                        const chapterTrackIds = trackWithChapters[0].chapterList;\n                        const chapterTracks = [...this.tracks.values()].filter(track => chapterTrackIds.indexOf(track.header.trackId) !== -1);\n                        if (chapterTracks.length === 1) {\n                            return this.parseChapterTrack(chapterTracks[0], trackWithChapters[0], len);\n                        }\n                    }\n                }\n                await this.tokenizer.ignore(len);\n            },\n            ftyp: async (len) => {\n                const types = [];\n                while (len > 0) {\n                    const ftype = await this.tokenizer.readToken(_AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.ftyp);\n                    len -= _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.ftyp.len;\n                    const value = ftype.type.replace(/\\W/g, '');\n                    if (value.length > 0) {\n                        types.push(value); // unshift for backward compatibility\n                    }\n                }\n                debug(`ftyp: ${types.join('/')}`);\n                const x = types.filter(distinct).join('/');\n                this.metadata.setFormat('container', x);\n            },\n            /**\n             * Parse sample description atom\n             */\n            stsd: async (len) => {\n                const stsd = await this.tokenizer.readToken(new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.StsdAtom(len));\n                const trackDescription = this.getTrackDescription();\n                trackDescription.soundSampleDescription = stsd.table.map(dfEntry => this.parseSoundSampleDescription(dfEntry));\n            },\n            /**\n             * Parse sample-sizes atom ('stsz')\n             */\n            stsz: async (len) => {\n                const stsz = await this.tokenizer.readToken(new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.StszAtom(len));\n                const td = this.getTrackDescription();\n                td.sampleSize = stsz.sampleSize;\n                td.sampleSizeTable = stsz.entries;\n            },\n            date: async (len) => {\n                const date = await this.tokenizer.readToken(new token_types__WEBPACK_IMPORTED_MODULE_1__.StringType(len, 'utf-8'));\n                await this.addTag('date', date);\n            }\n        };\n    }\n    static read_BE_Integer(array, signed) {\n        const integerType = (signed ? 'INT' : 'UINT') + array.length * 8 + (array.length > 1 ? '_BE' : '');\n        const token = token_types__WEBPACK_IMPORTED_MODULE_1__[integerType];\n        if (!token) {\n            throw new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.Mp4ContentError(`Token for integer type not found: \"${integerType}\"`);\n        }\n        return Number(token.get(array, 0));\n    }\n    async parse() {\n        this.hasVideoTrack = false;\n        this.hasAudioTrack = true;\n        this.tracks.clear();\n        let remainingFileSize = this.tokenizer.fileInfo.size || 0;\n        while (!this.tokenizer.fileInfo.size || remainingFileSize > 0) {\n            try {\n                const token = await this.tokenizer.peekToken(_AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.Header);\n                if (token.name === '\\0\\0\\0\\0') {\n                    const errMsg = `Error at offset=${this.tokenizer.position}: box.id=0`;\n                    debug(errMsg);\n                    this.addWarning(errMsg);\n                    break;\n                }\n            }\n            catch (error) {\n                if (error instanceof Error) {\n                    const errMsg = `Error at offset=${this.tokenizer.position}: ${error.message}`;\n                    debug(errMsg);\n                    this.addWarning(errMsg);\n                }\n                else\n                    throw error;\n                break;\n            }\n            const rootAtom = await _Atom_js__WEBPACK_IMPORTED_MODULE_4__.Atom.readAtom(this.tokenizer, (atom, remaining) => this.handleAtom(atom, remaining), null, remainingFileSize);\n            remainingFileSize -= rootAtom.header.length === BigInt(0) ? remainingFileSize : Number(rootAtom.header.length);\n        }\n        // Post process metadata\n        const formatList = [];\n        this.tracks.forEach(track => {\n            const trackFormats = [];\n            track.soundSampleDescription.forEach(ssd => {\n                const streamInfo = {};\n                const encoderInfo = encoderDict[ssd.dataFormat];\n                if (encoderInfo) {\n                    trackFormats.push(encoderInfo.format);\n                    streamInfo.codecName = encoderInfo.format;\n                }\n                else {\n                    streamInfo.codecName = `<${ssd.dataFormat}>`;\n                }\n                if (ssd.description) {\n                    const { description } = ssd;\n                    if (description.sampleRate > 0) {\n                        streamInfo.type = _type_js__WEBPACK_IMPORTED_MODULE_5__.TrackType.audio;\n                        streamInfo.audio = {\n                            samplingFrequency: description.sampleRate,\n                            bitDepth: description.sampleSize,\n                            channels: description.numAudioChannels\n                        };\n                    }\n                }\n                this.metadata.addStreamInfo(streamInfo);\n            });\n            if (trackFormats.length >= 1) {\n                formatList.push(trackFormats.join('/'));\n            }\n        });\n        if (formatList.length > 0) {\n            this.metadata.setFormat('codec', formatList.filter(distinct).join('+'));\n        }\n        const audioTracks = [...this.tracks.values()].filter(track => {\n            return track.soundSampleDescription.length >= 1 && track.soundSampleDescription[0].description && track.soundSampleDescription[0].description.numAudioChannels > 0;\n        });\n        if (audioTracks.length >= 1) {\n            const audioTrack = audioTracks[0];\n            if (audioTrack.media.header && audioTrack.media.header.timeScale > 0) {\n                if (audioTrack.media.header.duration > 0) {\n                    debug('Using duration defined on audio track');\n                    const duration = audioTrack.media.header.duration / audioTrack.media.header.timeScale; // calculate duration in seconds\n                    this.metadata.setFormat('duration', duration);\n                }\n                else if (audioTrack.fragments.length > 0) {\n                    debug('Calculate duration defined in track fragments');\n                    let totalTimeUnits = 0;\n                    for (const fragment of audioTrack.fragments) {\n                        const defaultDuration = fragment.header.defaultSampleDuration;\n                        for (const sample of fragment.trackRun.samples) {\n                            const dur = sample.sampleDuration ?? defaultDuration;\n                            if (dur == null) {\n                                throw new Error(\"Missing sampleDuration and no default_sample_duration in tfhd\");\n                            }\n                            totalTimeUnits += dur;\n                        }\n                    }\n                    this.metadata.setFormat('duration', totalTimeUnits / audioTrack.media.header.timeScale);\n                }\n            }\n            const ssd = audioTrack.soundSampleDescription[0];\n            if (ssd.description && audioTrack.media.header) {\n                this.metadata.setFormat('sampleRate', ssd.description.sampleRate);\n                this.metadata.setFormat('bitsPerSample', ssd.description.sampleSize);\n                this.metadata.setFormat('numberOfChannels', ssd.description.numAudioChannels);\n                if (audioTrack.media.header.timeScale === 0 && audioTrack.timeToSampleTable.length > 0) {\n                    const totalSampleSize = audioTrack.timeToSampleTable\n                        .map(ttstEntry => ttstEntry.count * ttstEntry.duration)\n                        .reduce((total, sampleSize) => total + sampleSize);\n                    const duration = totalSampleSize / ssd.description.sampleRate;\n                    this.metadata.setFormat('duration', duration);\n                }\n            }\n            const encoderInfo = encoderDict[ssd.dataFormat];\n            if (encoderInfo) {\n                this.metadata.setFormat('lossless', !encoderInfo.lossy);\n            }\n            this.calculateBitRate();\n        }\n        this.metadata.setFormat('hasAudio', this.hasAudioTrack);\n        this.metadata.setFormat('hasVideo', this.hasVideoTrack);\n    }\n    async handleAtom(atom, remaining) {\n        if (atom.parent) {\n            switch (atom.parent.header.name) {\n                case 'ilst':\n                case '<id>':\n                    return this.parseMetadataItemData(atom);\n                case 'moov':\n                    switch (atom.header.name) {\n                        case 'trak':\n                            return this.parseTrackBox(atom);\n                    }\n                    break;\n                case 'moof':\n                    switch (atom.header.name) {\n                        case 'traf':\n                            return this.parseTrackFragmentBox(atom);\n                    }\n            }\n        }\n        // const payloadLength = atom.getPayloadLength(remaining);\n        if (this.atomParsers[atom.header.name]) {\n            return this.atomParsers[atom.header.name](remaining);\n        }\n        debug(`No parser for atom path=${atom.atomPath}, payload-len=${remaining}, ignoring atom`);\n        await this.tokenizer.ignore(remaining);\n    }\n    getTrackDescription() {\n        // ToDo: pick the right track, not the last track!!!!\n        const tracks = [...this.tracks.values()];\n        return tracks[tracks.length - 1];\n    }\n    calculateBitRate() {\n        if (this.audioLengthInBytes && this.metadata.format.duration) {\n            this.metadata.setFormat('bitrate', 8 * this.audioLengthInBytes / this.metadata.format.duration);\n        }\n    }\n    async addTag(id, value) {\n        await this.metadata.addTag(tagFormat, id, value);\n    }\n    addWarning(message) {\n        debug(`Warning: ${message}`);\n        this.metadata.addWarning(message);\n    }\n    /**\n     * Parse data of Meta-item-list-atom (item of 'ilst' atom)\n     * @param metaAtom\n     * Ref: https://developer.apple.com/library/content/documentation/QuickTime/QTFF/Metadata/Metadata.html#//apple_ref/doc/uid/TP40000939-CH1-SW8\n     */\n    parseMetadataItemData(metaAtom) {\n        let tagKey = metaAtom.header.name;\n        return metaAtom.readAtoms(this.tokenizer, async (child, remaining) => {\n            const payLoadLength = child.getPayloadLength(remaining);\n            switch (child.header.name) {\n                case 'data': // value atom\n                    return this.parseValueAtom(tagKey, child);\n                case 'name': // name atom (optional)\n                case 'mean':\n                case 'rate': {\n                    const name = await this.tokenizer.readToken(new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.NameAtom(payLoadLength));\n                    tagKey += `:${name.name}`;\n                    break;\n                }\n                default: {\n                    const uint8Array = await this.tokenizer.readToken(new token_types__WEBPACK_IMPORTED_MODULE_1__.Uint8ArrayType(payLoadLength));\n                    this.addWarning(`Unsupported meta-item: ${tagKey}[${child.header.name}] => value=${(0,uint8array_extras__WEBPACK_IMPORTED_MODULE_6__.uint8ArrayToHex)(uint8Array)} ascii=${(0,uint8array_extras__WEBPACK_IMPORTED_MODULE_6__.uint8ArrayToString)(uint8Array, 'ascii')}`);\n                }\n            }\n        }, metaAtom.getPayloadLength(0));\n    }\n    async parseValueAtom(tagKey, metaAtom) {\n        const dataAtom = await this.tokenizer.readToken(new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.DataAtom(Number(metaAtom.header.length) - _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.Header.len));\n        if (dataAtom.type.set !== 0) {\n            throw new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.Mp4ContentError(`Unsupported type-set != 0: ${dataAtom.type.set}`);\n        }\n        // Use well-known-type table\n        // Ref: https://developer.apple.com/library/content/documentation/QuickTime/QTFF/Metadata/Metadata.html#//apple_ref/doc/uid/TP40000939-CH1-SW35\n        switch (dataAtom.type.type) {\n            case 0: // reserved: Reserved for use where no type needs to be indicated\n                switch (tagKey) {\n                    case 'trkn':\n                    case 'disk': {\n                        const num = token_types__WEBPACK_IMPORTED_MODULE_1__.UINT8.get(dataAtom.value, 3);\n                        const of = token_types__WEBPACK_IMPORTED_MODULE_1__.UINT8.get(dataAtom.value, 5);\n                        // console.log(\"  %s[data] = %s/%s\", tagKey, num, of);\n                        await this.addTag(tagKey, `${num}/${of}`);\n                        break;\n                    }\n                    case 'gnre': {\n                        const genreInt = token_types__WEBPACK_IMPORTED_MODULE_1__.UINT8.get(dataAtom.value, 1);\n                        const genreStr = _id3v1_ID3v1Parser_js__WEBPACK_IMPORTED_MODULE_7__.Genres[genreInt - 1];\n                        // console.log(\"  %s[data] = %s\", tagKey, genreStr);\n                        await this.addTag(tagKey, genreStr);\n                        break;\n                    }\n                    case 'rate': {\n                        const rate = new TextDecoder('ascii').decode(dataAtom.value);\n                        await this.addTag(tagKey, rate);\n                        break;\n                    }\n                    default:\n                        debug(`unknown proprietary value type for: ${metaAtom.atomPath}`);\n                }\n                break;\n            case 1: // UTF-8: Without any count or NULL terminator\n            case 18: // Unknown: Found in m4b in combination with a 'Â©gen' tag\n                await this.addTag(tagKey, new TextDecoder('utf-8').decode(dataAtom.value));\n                break;\n            case 13: // JPEG\n                if (this.options.skipCovers)\n                    break;\n                await this.addTag(tagKey, {\n                    format: 'image/jpeg',\n                    data: Uint8Array.from(dataAtom.value)\n                });\n                break;\n            case 14: // PNG\n                if (this.options.skipCovers)\n                    break;\n                await this.addTag(tagKey, {\n                    format: 'image/png',\n                    data: Uint8Array.from(dataAtom.value)\n                });\n                break;\n            case 21: // BE Signed Integer\n                await this.addTag(tagKey, MP4Parser.read_BE_Integer(dataAtom.value, true));\n                break;\n            case 22: // BE Unsigned Integer\n                await this.addTag(tagKey, MP4Parser.read_BE_Integer(dataAtom.value, false));\n                break;\n            case 65: // An 8-bit signed integer\n                await this.addTag(tagKey, token_types__WEBPACK_IMPORTED_MODULE_1__.UINT8.get(dataAtom.value, 0));\n                break;\n            case 66: // A big-endian 16-bit signed integer\n                await this.addTag(tagKey, token_types__WEBPACK_IMPORTED_MODULE_1__.UINT16_BE.get(dataAtom.value, 0));\n                break;\n            case 67: // A big-endian 32-bit signed integer\n                await this.addTag(tagKey, token_types__WEBPACK_IMPORTED_MODULE_1__.UINT32_BE.get(dataAtom.value, 0));\n                break;\n            default:\n                this.addWarning(`atom key=${tagKey}, has unknown well-known-type (data-type): ${dataAtom.type.type}`);\n        }\n    }\n    async parseTrackBox(trakBox) {\n        // @ts-ignore\n        const track = {\n            media: {},\n            fragments: []\n        };\n        await trakBox.readAtoms(this.tokenizer, async (child, remaining) => {\n            const payLoadLength = child.getPayloadLength(remaining);\n            switch (child.header.name) {\n                case 'chap': {\n                    const chap = await this.tokenizer.readToken(new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.ChapterTrackReferenceBox(remaining));\n                    track.chapterList = chap;\n                    break;\n                }\n                case 'tkhd': // TrackHeaderBox\n                    track.header = await this.tokenizer.readToken(new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.TrackHeaderAtom(payLoadLength));\n                    break;\n                case 'hdlr': // TrackHeaderBox\n                    track.handler = await this.tokenizer.readToken(new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.HandlerBox(payLoadLength));\n                    switch (track.handler.handlerType) {\n                        case 'audi':\n                            debug('Contains audio track');\n                            this.hasAudioTrack = true;\n                            break;\n                        case 'vide':\n                            debug('Contains video track');\n                            this.hasVideoTrack = true;\n                            break;\n                    }\n                    break;\n                case 'mdhd': { // Parse media header (mdhd) box\n                    const mdhd_data = await this.tokenizer.readToken(new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.MdhdAtom(payLoadLength));\n                    track.media.header = mdhd_data;\n                    break;\n                }\n                case 'stco': {\n                    const stco = await this.tokenizer.readToken(new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.StcoAtom(payLoadLength));\n                    track.chunkOffsetTable = stco.entries; // remember chunk offsets\n                    break;\n                }\n                case 'stsc': { // sample-to-Chunk box\n                    const stsc = await this.tokenizer.readToken(new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.StscAtom(payLoadLength));\n                    track.sampleToChunkTable = stsc.entries;\n                    break;\n                }\n                case 'stsd': { // sample description box\n                    const stsd = await this.tokenizer.readToken(new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.StsdAtom(payLoadLength));\n                    track.soundSampleDescription = stsd.table.map(dfEntry => this.parseSoundSampleDescription(dfEntry));\n                    break;\n                }\n                case 'stts': { // time-to-sample table\n                    const stts = await this.tokenizer.readToken(new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.SttsAtom(payLoadLength));\n                    track.timeToSampleTable = stts.entries;\n                    break;\n                }\n                case 'stsz': {\n                    const stsz = await this.tokenizer.readToken(new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.StszAtom(payLoadLength));\n                    track.sampleSize = stsz.sampleSize;\n                    track.sampleSizeTable = stsz.entries;\n                    break;\n                }\n                case 'dinf':\n                case 'vmhd':\n                case 'smhd':\n                    debug(`Ignoring: ${child.header.name}`);\n                    await this.tokenizer.ignore(payLoadLength);\n                    break;\n                default: {\n                    debug(`Unexpected track box: ${child.header.name}`);\n                    await this.tokenizer.ignore(payLoadLength);\n                }\n            }\n        }, trakBox.getPayloadLength(0));\n        // Register track\n        this.tracks.set(track.header.trackId, track);\n    }\n    parseTrackFragmentBox(trafBox) {\n        let tfhd;\n        return trafBox.readAtoms(this.tokenizer, async (child, remaining) => {\n            const payLoadLength = child.getPayloadLength(remaining);\n            switch (child.header.name) {\n                case 'tfhd': { // TrackFragmentHeaderBox\n                    const fragmentHeaderBox = new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.TrackFragmentHeaderBox(child.getPayloadLength(remaining));\n                    tfhd = await this.tokenizer.readToken(fragmentHeaderBox);\n                    break;\n                }\n                case 'tfdt': // TrackFragmentBaseMediaDecodeTimeBo\n                    await this.tokenizer.ignore(payLoadLength);\n                    break;\n                case 'trun': { // TrackRunBox\n                    const trackRunBox = new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.TrackRunBox(payLoadLength);\n                    const trun = await this.tokenizer.readToken(trackRunBox);\n                    if (tfhd) {\n                        const track = this.tracks.get(tfhd.trackId);\n                        track?.fragments.push({ header: tfhd, trackRun: trun });\n                    }\n                    break;\n                }\n                default: {\n                    debug(`Unexpected box: ${child.header.name}`);\n                    await this.tokenizer.ignore(payLoadLength);\n                }\n            }\n        }, trafBox.getPayloadLength(0));\n    }\n    /**\n     * @param sampleDescription\n     * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap3/qtff3.html#//apple_ref/doc/uid/TP40000939-CH205-128916\n     */\n    parseSoundSampleDescription(sampleDescription) {\n        const ssd = {\n            dataFormat: sampleDescription.dataFormat,\n            dataReferenceIndex: sampleDescription.dataReferenceIndex\n        };\n        let offset = 0;\n        if (sampleDescription.description) {\n            const version = _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.SoundSampleDescriptionVersion.get(sampleDescription.description, offset);\n            offset += _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.SoundSampleDescriptionVersion.len;\n            if (version.version === 0 || version.version === 1) {\n                // Sound Sample Description (Version 0)\n                ssd.description = _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.SoundSampleDescriptionV0.get(sampleDescription.description, offset);\n            }\n            else {\n                debug(`Warning: sound-sample-description ${version} not implemented`);\n            }\n        }\n        return ssd;\n    }\n    async parseChapterTrack(chapterTrack, track, len) {\n        if (!chapterTrack.sampleSize) {\n            if (chapterTrack.chunkOffsetTable.length !== chapterTrack.sampleSizeTable.length)\n                throw new Error('Expected equal chunk-offset-table & sample-size-table length.');\n        }\n        const chapters = [];\n        for (let i = 0; i < chapterTrack.chunkOffsetTable.length && len > 0; ++i) {\n            const start = chapterTrack.timeToSampleTable\n                .slice(0, i)\n                .reduce((acc, cur) => acc + cur.duration, 0);\n            const chunkOffset = chapterTrack.chunkOffsetTable[i];\n            const nextChunkLen = chunkOffset - this.tokenizer.position;\n            const sampleSize = chapterTrack.sampleSize > 0 ? chapterTrack.sampleSize : chapterTrack.sampleSizeTable[i];\n            len -= nextChunkLen + sampleSize;\n            if (len < 0)\n                throw new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.Mp4ContentError('Chapter chunk exceeding token length');\n            await this.tokenizer.ignore(nextChunkLen);\n            const title = await this.tokenizer.readToken(new _AtomToken_js__WEBPACK_IMPORTED_MODULE_3__.ChapterText(sampleSize));\n            debug(`Chapter ${i + 1}: ${title}`);\n            const chapter = {\n                title,\n                timeScale: chapterTrack.media.header ? chapterTrack.media.header.timeScale : 0,\n                start,\n                sampleOffset: this.findSampleOffset(track, this.tokenizer.position)\n            };\n            debug(`Chapter title=${chapter.title}, offset=${chapter.sampleOffset}/${track.header.duration}`); // ToDo, use media duration if required!!!\n            chapters.push(chapter);\n        }\n        this.metadata.setFormat('chapters', chapters);\n        await this.tokenizer.ignore(len);\n    }\n    findSampleOffset(track, chapterOffset) {\n        let chunkIndex = 0;\n        while (chunkIndex < track.chunkOffsetTable.length && track.chunkOffsetTable[chunkIndex] < chapterOffset) {\n            ++chunkIndex;\n        }\n        return this.getChunkDuration(chunkIndex + 1, track);\n    }\n    getChunkDuration(chunkId, track) {\n        let ttsi = 0;\n        let ttsc = track.timeToSampleTable[ttsi].count;\n        let ttsd = track.timeToSampleTable[ttsi].duration;\n        let curChunkId = 1;\n        let samplesPerChunk = this.getSamplesPerChunk(curChunkId, track.sampleToChunkTable);\n        let totalDuration = 0;\n        while (curChunkId < chunkId) {\n            const nrOfSamples = Math.min(ttsc, samplesPerChunk);\n            totalDuration += nrOfSamples * ttsd;\n            ttsc -= nrOfSamples;\n            samplesPerChunk -= nrOfSamples;\n            if (samplesPerChunk === 0) {\n                ++curChunkId;\n                samplesPerChunk = this.getSamplesPerChunk(curChunkId, track.sampleToChunkTable);\n            }\n            else {\n                ++ttsi;\n                ttsc = track.timeToSampleTable[ttsi].count;\n                ttsd = track.timeToSampleTable[ttsi].duration;\n            }\n        }\n        return totalDuration;\n    }\n    getSamplesPerChunk(chunkId, stcTable) {\n        for (let i = 0; i < stcTable.length - 1; ++i) {\n            if (chunkId >= stcTable[i].firstChunk && chunkId < stcTable[i + 1].firstChunk) {\n                return stcTable[i].samplesPerChunk;\n            }\n        }\n        return stcTable[stcTable.length - 1].samplesPerChunk;\n    }\n}\n//# sourceMappingURL=MP4Parser.js.map\n\n//# sourceURL=webpack:///./node_modules/music-metadata/lib/mp4/MP4Parser.js?\n}");

/***/ })

}]);